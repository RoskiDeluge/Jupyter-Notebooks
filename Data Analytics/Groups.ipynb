{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7506d854-3d68-408c-876c-be95ca19f5af",
   "metadata": {},
   "source": [
    "groupby() takes some df, splits it into chuncks based on some key values, applies computation on those chunks, then combines the results back together into another df. In pandas this is referred to as the split-apply-combine pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6771e75c-a367-403d-97f7-462a314efc33",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "312e63a6-be63-4dda-a8f1-9a8d646dfe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febdc5e0-41aa-4774-a675-a4599569faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('path/to/dataset.csv')\n",
    "# Exclude state level summarizations which have a sum level value of 40\n",
    "df = df[df['SUMLEV']==50]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e63efe-1cc1-4eb1-ab14-4a88f2be391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the first example of without groupby() let's use census date. Get a list of unique states, then iterate over\n",
    "# the states and for each state we reduce the df and calculate the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde7671-3cd2-4077-b82b-7ba58b90610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in df['STNAME'].unique():\n",
    "    # We'll just calculate the avg using np\n",
    "    avg = np.average(df.where(df['STNAME']==state).dropna()['CENSUS2010POP'])\n",
    "    print('Counties in state ' + state + ' have an average population of ' + str(avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a31fb60-17f9-415c-aae7-3e536ceeb8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a second approach using groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdad9ce-ce23-4282-8483-9e3de67af16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, frame in df.groupby('STNAME'):\n",
    "    # 1. Split step\n",
    "    # groupby() returns a tuple, where the first value is the value of the key we're trying to group by,\n",
    "    # in this case a specific state name, and the second one is the projected df that was found for that group.\n",
    "    \n",
    "    # 2. Apply step\n",
    "    # Calculate and avg of the census2010pop\n",
    "    avg = np.average(frame['CENSUS2010POP'])\n",
    "    \n",
    "    # And print the result\n",
    "    print('Counties in state ' + group + ' have an average population of ' + str(avg))\n",
    "    \n",
    "    # 3. Combine step\n",
    "    # We don't have to worry about the combine step in this case because all of our data transformation is \n",
    "    # actually printing out the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a20b9d-ceb9-4f7f-93ea-3373517dab9f",
   "metadata": {},
   "source": [
    "99% of the time, you'll use groupby on one or more columns. But you can also provide a function to groupby and use that to segment your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdbb838-d1b1-4281-9e77-78584ffd8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('STNAME')\n",
    "\n",
    "def set_batch_number():\n",
    "    if item[0] < 'M':\n",
    "        return 0\n",
    "    if item[0] < 'Q':\n",
    "        return 1\n",
    "    return 2\n",
    "\n",
    "# The df is supposed to be grouped by according to the batch number and we'll loop through each batch group.\n",
    "for group, frame in df.groupby(set_batch_number):\n",
    "    print('There are ' + str(len(frame)) + ' records in group ' + str(group) + ' for processing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fe8861-64e2-4653-ae24-5838741706de",
   "metadata": {},
   "source": [
    "One more example of groupby. Using dataset of housing data from airbnb. In this dataset there are two columns of interest, cancellation_policy and review_scores_value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be841ef1-c10d-44f8-a410-3d0e687802ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('path/to/dataset.csv')\n",
    "# So, how would I groupby both of the columns? A first approach might be to promote them to a multi-index\n",
    "# and just call groupby()\n",
    "df = df.set_index(['cancellation_policy', 'review_scores_value'])\n",
    "\n",
    "# When we have a multi-index we need to pass in the levels we are interested in grouping by.\n",
    "for group, frame in df.groupby(level=(0,1)):\n",
    "    pring(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2d24d1-5e62-4061-95a7-179271a57361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works ok. But what if we wanted to groupby the cancellation policy and review scores, but\n",
    "# separate out all the 10's from those under 10? In this case we could use a function to manage the \n",
    "# groupings.\n",
    "def grouping_fun(item):\n",
    "    # Check the \"review_scores_value\" portion of the index. \n",
    "    # item is in the format of (cancellation_policy, review_scores_value), a tuple\n",
    "    if item[1] == 10.0:\n",
    "        return (item[0], \"10.0\")\n",
    "    else:\n",
    "        return (item[0], \"not 10.0\")\n",
    "    \n",
    "for group, frame in df.groupby(by=grouping_fun):\n",
    "    print(group)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e6342-1e1a-4f1b-851c-695b42116b7b",
   "metadata": {},
   "source": [
    "# Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57eb183-56cf-4599-b3c7-74a843414478",
   "metadata": {},
   "source": [
    "The most straightforward apply step is the aggregation of data, and uses the method agg() on the groupby object. \n",
    "Above, we simply iterated over the groupby object, unpacking it into a label (the group name) and a df. But with agg we can pass in a dict of the columns we are interested in aggregating along with the function we are looking to apply to aggregate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a253a-11a5-402e-82d5-73d4beb8ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "\n",
    "# Let's group by cancellation policy and find the avg review scores value by group\n",
    "df.groupby('cancellation_policy').agg({'review_scores_value':np.nanmean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3135ab3-3e12-4019-81fb-3e8a49a8e714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can just extend this dictionary to aggregate by multiple functions or multiple columns\n",
    "df.groupby('cancellation_policy').agg({'review_scores_value':(np.nanmean,np.nanstd),\n",
    "                                       'reviews_per_month':np.nanmean})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a05348e-4e1d-4967-b26f-6e8f77c43d12",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6516b5-a0f5-4ba3-a211-f1d5da33f946",
   "metadata": {},
   "source": [
    "Transformation is different from aggregation. Where agg() returns a single value per column, so one row per group, transform() returns an object that is the same size as the group. Essentially, it broadcasts the function you supply over the grouped df, returning a new df. This makes combining data later quite easy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653ebedd-77a5-42cf-b3b4-fcf912e5f77f",
   "metadata": {},
   "source": [
    "For instance, suppose we wanted to include the avg rating values in a given group by cancellation policy, but preserve the df shape so that we could generate a difference between an individual observation and the sum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5e167-4c8a-4ec1-b98c-ac22889cedc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's define some subset of the columns we're interested in\n",
    "cols = ['cancellation_policy', 'review_score_value']\n",
    "\n",
    "# Now, let's transform it. I'll store this in it's own df.\n",
    "transform_df = df[cols].groupby('cancellation_policy').transform(np.nanmean)\n",
    "transform_df.head()\n",
    "\n",
    "# We can join in this df since it's index is the same as the original df. \n",
    "# Before we do that, let's rename the column in the transformed version\n",
    "transform_df.rename({'review_scores_value': 'mean_review_scores'}, axis='columns', inplace=True)\n",
    "\n",
    "df = df.merge(transform_df, left_index=True, right_index=True)\n",
    "df.head()\n",
    "\n",
    "# Our new column is in place, the mean review scores.\n",
    "# So now we could create, for instance, the difference between a given row and \n",
    "# its group (the cancellation policy) means.\n",
    "\n",
    "df['mean_diff'] = np.absolute(df['review_scores_value'] - df['mean_review_scores'])\n",
    "df['mean_diff'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6f11e0-daa9-49f2-9ea9-2eed9c8ced49",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcab3451-c93a-4daf-a7ba-fa9996887883",
   "metadata": {},
   "source": [
    "The groupby object has built in support for filtering groups as well. Often you'll want to group by some feature, then make some transformation to the groups, then drop certain groups as part of your cleaning routine. \n",
    "\n",
    "The filter function takes in a function which it applies to each group dataframe and returns either a True or False, depending on whether that group should be included in the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac438f49-a5d5-4ab7-aab0-b2d11237dcb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# For instance, if we wanted only those groups that had a mean rating above 9 included in our results\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcancellation_policy\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mnanmean(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview_scores_value\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m9.2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# For instance, if we wanted only those groups that had a mean rating above 9 included in our results\n",
    "df.groupby('cancellation_policy').filter(lambda x: np.nanmean(x['review_scores_value']) > 9.2)\n",
    "\n",
    "# The results are still indexed, but any of the results which were in a group with a mean review score\n",
    "# of less than or equal to 9.2 were not copied over."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a583aa-4773-487a-840d-37c9f64599f2",
   "metadata": {},
   "source": [
    "# Applying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71b25c-f953-4c90-adc9-d7da7c0e4f5b",
   "metadata": {},
   "source": [
    "By far the most common operation invoked on groupby objects is the apply() function. This allows you to apply an arbitrary function to each group, and stitch the results back for each apply() into a single df where the index is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aed208e-2f53-4215-b22b-b462496b3396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at an example using the Airbnb dataset\n",
    "df = pd.read_csv('path/to/dataset.csv')\n",
    "\n",
    "# Let's include some of the columns we're interested in.\n",
    "df = df[['cancellation_policy', 'review_scores_value']]\n",
    "df.head()\n",
    "\n",
    "# In previous work we wanted to find the average review score of a listing and its deviation from the group mean. \n",
    "# This was a two step process. First we used transform() on the groupby object and then we had to broadcast to \n",
    "# create a new column. With apply we could wrap this logic in one place. \n",
    "def calc_mean_review_scores(group):\n",
    "    #group is a df of whatever we have groupedby, eg. 'cancellation_policy'\n",
    "    # so we can treat this as a complete df.\n",
    "    avg = np.nanmean(group['review_scores_value'])\n",
    "    group['review_scores_mean'] = np.abs(avg - group['review_scores_value'])\n",
    "    return group\n",
    "\n",
    "# Now apply this to all of the groups\n",
    "df.groupby('cancellation_policy').apply(calc_mean_review_scores).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36df0151-e425-4cb1-a79f-b2f833689572",
   "metadata": {},
   "source": [
    "groupby is a powerful tool commonly used for data cleaning and data analysis. Once you have grouped the data by some category, you have a df of just those values and you can conduct aggregate analysis on the segments you're interested in. The groupby function follows a split-apply-combine approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
